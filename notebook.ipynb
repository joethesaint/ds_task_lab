{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFOlKngEO961BKjP3JeMvg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5af0120625204da8873678a9604b346f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a5d2eca84204f4f95bdff24f5bde223",
              "IPY_MODEL_e855cfa6332f4c02ac4ff6bc1392fda2",
              "IPY_MODEL_fd3cb9d571ee4a82a0f08ddf571776d6"
            ],
            "layout": "IPY_MODEL_5f03847bf39643ffa8e655dae26c1708"
          }
        },
        "9a5d2eca84204f4f95bdff24f5bde223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e34aacf387874ca38e528033580a8416",
            "placeholder": "​",
            "style": "IPY_MODEL_f448a53169f444a6807808adf5de4bce",
            "value": "100%"
          }
        },
        "e855cfa6332f4c02ac4ff6bc1392fda2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9ad4f0f83b74d228fe63829784ef023",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_84f16e5b31c144fc800e50e95df597a2",
            "value": 2
          }
        },
        "fd3cb9d571ee4a82a0f08ddf571776d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60e3840abbf0406cac910803e4401399",
            "placeholder": "​",
            "style": "IPY_MODEL_d2a693afc81a4d738d4b40dc50ba8709",
            "value": " 2/2 [00:12&lt;00:00,  6.10s/it]"
          }
        },
        "5f03847bf39643ffa8e655dae26c1708": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e34aacf387874ca38e528033580a8416": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f448a53169f444a6807808adf5de4bce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9ad4f0f83b74d228fe63829784ef023": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84f16e5b31c144fc800e50e95df597a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60e3840abbf0406cac910803e4401399": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2a693afc81a4d738d4b40dc50ba8709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d7d62d713564809838d28f34bd93db0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5da3fd56e504f4fb68cfae0df2152a2",
              "IPY_MODEL_bbd80782360949a6909b4dbb88e9490c",
              "IPY_MODEL_3d03751a1bc34ce5a44635de70f1ebd0"
            ],
            "layout": "IPY_MODEL_eb5f678823ad41f3b0fc3a01af93fff0"
          }
        },
        "a5da3fd56e504f4fb68cfae0df2152a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67975d8fec5f4b7db71df37095dec362",
            "placeholder": "​",
            "style": "IPY_MODEL_1ca5d0e3341a4d19ab67fb3ff405b61c",
            "value": "Generating embeddings:   0%"
          }
        },
        "bbd80782360949a6909b4dbb88e9490c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fca8690810834b17bd83d09c33a5c8d0",
            "max": 78,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_decc37a73d304c0eb7133302ab14fd72",
            "value": 0
          }
        },
        "3d03751a1bc34ce5a44635de70f1ebd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4cffe05495e45b990cede2e431cca81",
            "placeholder": "​",
            "style": "IPY_MODEL_d9ae6a3fef084a8680173d2fb4a34add",
            "value": " 0/78 [00:00&lt;?, ?it/s]"
          }
        },
        "eb5f678823ad41f3b0fc3a01af93fff0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67975d8fec5f4b7db71df37095dec362": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ca5d0e3341a4d19ab67fb3ff405b61c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fca8690810834b17bd83d09c33a5c8d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "decc37a73d304c0eb7133302ab14fd72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4cffe05495e45b990cede2e431cca81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9ae6a3fef084a8680173d2fb4a34add": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joethesaint/ds_task_lab/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbdyzkDN0zkf",
        "outputId": "cd7b87b1-a26b-42c1-b2a9-a7cdd81f5961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.15).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt install git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone http://23.29.118.76:3000/Test/ds_task_1ab.git\n",
        "!ls -a ds_task_1ab/.DS_Store"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ukc6H01m1FTE",
        "outputId": "e1047972-b863-48a9-a387-9f1edf225ed0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ds_task_1ab/.DS_Store\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16c585af"
      },
      "source": [
        "# Task\n",
        "Summarize the `README.md` file located at `/content/ds_task_1ab/README.md` and propose next steps for the project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58934aef"
      },
      "source": [
        "## Read README\n",
        "\n",
        "### Subtask:\n",
        "Read the content of the `README.md` file located at `/content/ds_task_1ab/README.md`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35e18fb4"
      },
      "source": [
        "**Reasoning**:\n",
        "To read the content of the `README.md` file, I will use Python's built-in file handling to open the file in read mode and print its content.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "348de4df",
        "outputId": "b343de29-7ef8-491e-f869-898a60250025"
      },
      "source": [
        "with open('/content/ds_task_1ab/README.md', 'r') as file:\n",
        "    readme_content = file.read()\n",
        "    print(readme_content)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Project Overview\n",
            "\n",
            "This project is divided into four main modules, each focusing on a distinct aspect of the system's development. The modules are designed to work together seamlessly, culminating in a comprehensive solution for product recommendation, OCR-based query processing, and image-based product detection.\n",
            "\n",
            "## Module 1: Data Preparation and Backend Setup\n",
            "\n",
            "### Task 1: E-commerce Dataset Cleaning\n",
            "\n",
            "- *Objective*: Ensure the dataset is clean and ready for analysis and vectorization.\n",
            "- *Key Actions*: Remove duplicates, handle missing values, and standardize formats.\n",
            "\n",
            "### Task 2: Vector Database Creation\n",
            "\n",
            "- *Objective*: Set up a vector database using Pinecone to store product vectors.\n",
            "- *Key Actions*: Define the database schema and integrate with Pinecone.\n",
            "\n",
            "### Task 3: Similarity Metrics Selection\n",
            "\n",
            "- *Objective*: Choose and justify the similarity metrics used to compare product vectors.\n",
            "- *Key Actions*: Evaluate different metrics (e.g., cosine similarity, dot product) and select the best fit based on the dataset characteristics.\n",
            "\n",
            "### Endpoint 1: Product Recommendation Service\n",
            "\n",
            "- *Functionality*: Handle natural language queries to recommend products, including safeguards against bad queries and sensitive data exposure.\n",
            "- *Input*: Customer's natural language query.\n",
            "- *Output*: Product matches array and a natural language response within specified constraints.\n",
            "\n",
            "## Module 2: OCR and Web Scraping\n",
            "\n",
            "### Task 4: OCR Functionality Implementation\n",
            "\n",
            "- *Objective*: Develop the capability to extract text from images using OCR technology.\n",
            "- *Key Actions*: Integrate and configure an OCR tool (e.g., Tesseract).\n",
            "\n",
            "### Task 5: Web Scraping for Product Images\n",
            "\n",
            "- *Objective*: Scrape product images from e-commerce websites for training data ``CNN_Model_Train_Data.csv``.\n",
            "- *Key Actions*: Automate scraping, download images, and store them systematically and make sure you have enough data to train the CNN model.\n",
            "\n",
            "### Endpoint 2: OCR-Based Query Processing\n",
            "\n",
            "- *Functionality*: Extract and process handwritten queries using the same logic as Endpoint 1.\n",
            "- *Input*: Image file with handwritten text.\n",
            "- *Output*: Same output format as Endpoint 1, adapted for image inputs also return the extracted test from OCR.\n",
            "\n",
            "## Module 3: CNN Model Development\n",
            "\n",
            "### Task 6: CNN Model Training\n",
            "\n",
            "- *Objective*: Develop a CNN model from scratch using only the ``products`` mentioned on ``CNN_Model_Train_Data.csv`` to identify products from images.\n",
            "- *Key Actions*: Train the model using scraped images and clean data without using pre-trained models.\n",
            "\n",
            "### Endpoint 3: Image-Based Product Detection\n",
            "\n",
            "- *Functionality*: Use the CNN model to identify products from images and match them using the vector database.\n",
            "- *Input*: Product image.\n",
            "- *Output*: Product description and matching products in a format consistent with other endpoints. Also return the name of the `class` that you got from CNN model for the particular input image.\n",
            "\n",
            "## Module 4: Frontend Development and Integration\n",
            "\n",
            "### Frontend Page 1: Text Query Interface\n",
            "\n",
            "- *Features*: Form to submit text queries, display natural language responses, and a product details table.\n",
            "\n",
            "### Frontend Page 2: Image Query Interface\n",
            "\n",
            "- *Features*: Allows users to upload images of handwritten queries and displays results similar to Page 1.\n",
            "\n",
            "### Frontend Page 3: Product Image Upload Interface\n",
            "\n",
            "- *Features*: Users can upload product images, and view the identified product description and related products in natural language and tabular format.\n",
            "\n",
            "## Instructions for Presentation\n",
            "\n",
            "### 1. Incremental Report Writing\n",
            "\n",
            "Each module completion should be accompanied by a concise, to-the-point report that documents the process, decisions, and outcomes. These reports will be incremental, building upon each other as the bootcamp progresses.\n",
            "\n",
            "#### Report Format Suggestion:\n",
            "\n",
            "- *Title Page*: Include the module number and title, the names of the team members, and the submission date.\n",
            "- *Introduction*: Briefly describe the objectives of the module and its importance to the overall project.\n",
            "- *High-Level Flow*:\n",
            "  - *Description*: Outline the main tasks and functionalities developed in the module.\n",
            "  - *Diagrams*: Include flowcharts or diagrams that visually represent the architecture and data flow.\n",
            "  - *Key Decisions*: Summarize crucial decisions made during the module, such as choice of technology, design patterns, and configurations.\n",
            "- *Challenges and Solutions*:\n",
            "  - Briefly discuss any challenges faced during the module and how they were addressed.\n",
            "- *Conclusion*: Sum up the outcomes of the module and its readiness for integration with other modules.\n",
            "- *References*: Cite any tools, libraries, or external resources that were used.\n",
            "\n",
            "### 2. Video Documentation\n",
            "\n",
            "Participants are required to create two sets of videos for each module, detailing both the functionality and the technical implementation. This will not only aid in a better understanding of the project but also serve as a reference for future projects.\n",
            "\n",
            "#### Video Requirements:\n",
            "\n",
            "- *Functional Demonstration Video*:\n",
            "  - *Content*: Demonstrate the functionality of each endpoint and page developed in the module.\n",
            "  - *Focus*: Show how the system responds to various inputs and scenarios. Explain the user interaction with the system.\n",
            "  - *Duration*: Keep the video concise, preferably under 5 minutes.\n",
            "- *Code Explanation Video*:\n",
            "  - *Content*: Provide a high-level overview of the codebase for the module.\n",
            "  - *Focus*: Explain the structure of the code, major classes, and functions. Highlight any significant patterns or algorithms used.\n",
            "  - *Duration*: Limit the explanation to under 10 minutes.\n",
            "\n",
            "### Submission Guidelines:\n",
            "\n",
            "- *Timing*: Submit the videos along with the incremental report at the end of each module.\n",
            "- *Format*: Ensure videos are in a common format (e.g., MP4) and quality is sufficient for clear viewing.\n",
            "- *Hosting*: Upload videos to a platform accessible to all participants and reviewers (e.g., Google Drive, YouTube in unlisted mode). Or you can use loom, fluvid, vmaker etc alternatively.\n",
            "\n",
            "## Instructions for Coding\n",
            "\n",
            "### General Guidelines\n",
            "\n",
            "- *Class-Based Implementation*: It is recommended to use class-based implementation for all backend services to ensure organized, reusable, and maintainable code.\n",
            "- *Best Practices*:\n",
            "  - *ACID Properties*: Ensure that database transactions are Atomic, Consistent, Isolated, and Durable to maintain data integrity and reliability.\n",
            "  - *Modularity*: Build the codebase with clear modularity in mind. Separate different functionalities into distinct modules to enhance readability and maintainability.\n",
            "- *Packaging*: Organize your code into packages that reflect the services they provide. This approach not only helps in maintaining the code but also simplifies the deployment and scaling process.\n",
            "- Directories: Whenever you will test on notebook make sure you keep all the notebooks in ``notebook`` directory and use proper naming for the notebooks.\n",
            "\n",
            "### Tech Stack\n",
            "\n",
            "- *Web Framework*: Use Flask for developing the backend. Flask provides flexibility and ease of use for setting up API services.\n",
            "- *Vector Database*: Integrate Pinecone to manage and query vector data efficiently. Pinecone supports scalable vector searches which are crucial for the recommendation systems in this project.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "533a9adb"
      },
      "source": [
        "### Summary of `README.md`\n",
        "\n",
        "The project aims to develop a comprehensive solution for product recommendation, OCR-based query processing, and image-based product detection, divided into four main modules:\n",
        "\n",
        "**Module 1: Data Preparation and Backend Setup**\n",
        "- **Task 1: E-commerce Dataset Cleaning**: Clean the dataset (remove duplicates, handle missing values, standardize formats).\n",
        "- **Task 2: Vector Database Creation**: Set up a Pinecone vector database.\n",
        "- **Task 3: Similarity Metrics Selection**: Choose and justify similarity metrics.\n",
        "- **Endpoint 1: Product Recommendation Service**: Handle natural language queries for product recommendations.\n",
        "\n",
        "**Module 2: OCR and Web Scraping**\n",
        "- **Task 4: OCR Functionality Implementation**: Develop OCR to extract text from images.\n",
        "- **Task 5: Web Scraping for Product Images**: Scrape product images for `CNN_Model_Train_Data.csv`.\n",
        "- **Endpoint 2: OCR-Based Query Processing**: Process handwritten queries from images.\n",
        "\n",
        "**Module 3: CNN Model Development**\n",
        "- **Task 6: CNN Model Training**: Develop and train a CNN model from scratch using `CNN_Model_Train_Data.csv` to identify products from images.\n",
        "- **Endpoint 3: Image-Based Product Detection**: Use the CNN model to identify products and match them using the vector database.\n",
        "\n",
        "**Module 4: Frontend Development and Integration**\n",
        "- **Frontend Page 1: Text Query Interface**\n",
        "- **Frontend Page 2: Image Query Interface**\n",
        "- **Frontend Page 3: Product Image Upload Interface**\n",
        "\n",
        "**Instructions for Presentation** include incremental report writing and video documentation for each module.\n",
        "\n",
        "**Instructions for Coding** emphasize class-based implementation, best practices (ACID, Modularity), packaging, and directory structure. The **Tech Stack** specifies Flask for the backend and Pinecone for the vector database."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "839ce475"
      },
      "source": [
        "### Proposed Next Steps for the Project\n",
        "\n",
        "Given the comprehensive overview in the `README.md`, the project should proceed in a modular fashion, following the outlined structure. The immediate next steps should focus on completing **Module 1: Data Preparation and Backend Setup**.\n",
        "\n",
        "1.  **Start Module 1: Data Preparation and Backend Setup**\n",
        "    *   **Task 1: E-commerce Dataset Cleaning**: The first priority is to clean the existing e-commerce dataset. This includes:\n",
        "        *   Identifying and removing duplicate entries.\n",
        "        *   Handling missing values appropriately (e.g., imputation, removal).\n",
        "        *   Standardizing data formats (e.g., product names, descriptions, categories) to ensure consistency.\n",
        "        *   *Action*: Load the `dataset.csv` and `CNN_Model_Train_Data.csv` into DataFrames and perform initial data quality checks.\n",
        "    *   **Task 2: Vector Database Creation (Pinecone)**: Once the dataset is clean, the next step is to prepare for vectorization and set up the vector database.\n",
        "        *   *Action*: Define the schema for product vectors and establish connection with Pinecone.\n",
        "    *   **Task 3: Similarity Metrics Selection**: Concurrently with vector database setup, research and select the most appropriate similarity metrics for product comparison.\n",
        "        *   *Action*: Evaluate cosine similarity, dot product, and other relevant metrics based on the nature of the product data.\n",
        "    *   **Endpoint 1: Product Recommendation Service**: Begin planning the architecture and implementation details for the natural language query endpoint.\n",
        "        *   *Action*: Design the API interface and consider safeguards against bad queries and sensitive data exposure.\n",
        "\n",
        "2.  **Plan for Module 2: OCR and Web Scraping**\n",
        "    *   While Module 1 is in progress, begin preliminary research for OCR tools (e.g., Tesseract) and web scraping strategies. Identify potential data sources for product images for `CNN_Model_Train_Data.csv`.\n",
        "\n",
        "3.  **Establish Version Control and Reporting Protocols**\n",
        "    *   Ensure all team members are familiar with Git for version control. Adhere to the specified incremental report writing and video documentation requirements for each module's completion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be193e2c"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The task asked to summarize the `README.md` file and propose next steps for the project. The summary of the `README.md` has been provided, outlining the project's structure, modules, and technical requirements. Additionally, a detailed proposal for the immediate next steps has been given, prioritizing Module 1 tasks.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The project is structured into four main modules:\n",
        "    *   **Module 1: Data Preparation and Backend Setup**: Encompasses e-commerce dataset cleaning, Pinecone vector database creation, similarity metrics selection, and a product recommendation service.\n",
        "    *   **Module 2: OCR and Web Scraping**: Focuses on implementing OCR functionality and web scraping product images.\n",
        "    *   **Module 3: CNN Model Development**: Involves training a CNN model from scratch for image-based product detection.\n",
        "    *   **Module 4: Frontend Development and Integration**: Includes creating three distinct frontend pages for text queries, image queries, and product image uploads.\n",
        "*   The `README.md` specifies instructions for presentation (incremental report writing, video documentation for each module) and coding best practices (class-based implementation, ACID principles, modularity, packaging, and directory structure).\n",
        "*   The specified tech stack includes Flask for the backend and Pinecone for the vector database.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The project should immediately commence with **Module 1: Data Preparation and Backend Setup**, prioritizing e-commerce dataset cleaning (handling duplicates, missing values, standardization), setting up the Pinecone vector database, selecting appropriate similarity metrics, and designing the Product Recommendation Service endpoint.\n",
        "*   Concurrently, initiate preliminary research for **Module 2: OCR and Web Scraping** tools and strategies, and establish robust version control and reporting protocols as outlined in the `README.md` to ensure project cohesion and documentation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a02d78f3"
      },
      "source": [
        "# Task\n",
        "Load 'dataset.csv' and 'CNN_Model_Train_Data.csv' into pandas DataFrames to begin initial inspection and data quality checks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f543cbba"
      },
      "source": [
        "## Load Datasets\n",
        "\n",
        "### Subtask:\n",
        "Load 'dataset.csv' and 'CNN_Model_Train_Data.csv' into pandas DataFrames to begin initial inspection and data quality checks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5479b55f"
      },
      "source": [
        "**Reasoning**:\n",
        "To load the datasets and perform initial inspection, I will use pandas to read the CSV files into DataFrames and then display the first few rows and column information for each.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "103a4697",
        "outputId": "c719db84-3780-48fa-85ab-9f32279e3b02"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load 'dataset.csv' into df_dataset\n",
        "df_dataset = pd.read_csv('/content/dataset.csv')\n",
        "\n",
        "# Load 'CNN_Model_Train_Data.csv' into df_cnn_train_data\n",
        "df_cnn_train_data = pd.read_csv('/content/CNN_Model_Train_Data.csv')\n",
        "\n",
        "print(\"\\n--- df_dataset Head ---\\n\")\n",
        "print(df_dataset.head())\n",
        "print(\"\\n--- df_dataset Info ---\\n\")\n",
        "df_dataset.info()\n",
        "\n",
        "print(\"\\n--- df_cnn_train_data Head ---\\n\")\n",
        "print(df_cnn_train_data.head())\n",
        "print(\"\\n--- df_cnn_train_data Info ---\\n\")\n",
        "df_cnn_train_data.info()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- df_dataset Head ---\n",
            "\n",
            "  InvoiceNo StockCode                           Description Quantity  \\\n",
            "0    536365    85123A    WHITE HANGING HEART T-LIGHT HOLDER        6   \n",
            "1    536365     71053                   WHITE METAL LANTERN        6   \n",
            "2    536365  ö84406B^        CREAM CUPID HEARTS COAT HANGER        8   \n",
            "3    536365    84029G  $KNITTED UNION FLAG HOT WATER BOTTLE       6@   \n",
            "4    536365    84029E       $RED WOOLLY HOTTIE WHITE HEART.       6@   \n",
            "\n",
            "           InvoiceDate UnitPrice CustomerID              Country  \n",
            "0  2010-12-01 08:26:00      2.55    17850.0  XxYUnited Kingdom☺️  \n",
            "1  2010-12-01 08:26:00      3.39    17850.0       United Kingdom  \n",
            "2  2010-12-01 08:26:00      2.75  &17850.0#  XxYUnited Kingdom☺️  \n",
            "3  2010-12-01 08:26:00      3.39    17850.0       United Kingdom  \n",
            "4  2010-12-01 08:26:00      3.39  &17850.0#       United Kingdom  \n",
            "\n",
            "--- df_dataset Info ---\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 541909 entries, 0 to 541908\n",
            "Data columns (total 8 columns):\n",
            " #   Column       Non-Null Count   Dtype \n",
            "---  ------       --------------   ----- \n",
            " 0   InvoiceNo    541909 non-null  object\n",
            " 1   StockCode    541909 non-null  object\n",
            " 2   Description  540884 non-null  object\n",
            " 3   Quantity     541909 non-null  object\n",
            " 4   InvoiceDate  541909 non-null  object\n",
            " 5   UnitPrice    541909 non-null  object\n",
            " 6   CustomerID   433909 non-null  object\n",
            " 7   Country      541909 non-null  object\n",
            "dtypes: object(8)\n",
            "memory usage: 33.1+ MB\n",
            "\n",
            "--- df_cnn_train_data Head ---\n",
            "\n",
            "  StockCode\n",
            "0   ö22384^\n",
            "1   ö22727^\n",
            "2   ö22112^\n",
            "3   ö23298^\n",
            "4   ö20726^\n",
            "\n",
            "--- df_cnn_train_data Info ---\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10 entries, 0 to 9\n",
            "Data columns (total 1 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   StockCode  10 non-null     object\n",
            "dtypes: object(1)\n",
            "memory usage: 212.0+ bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b2dd4be"
      },
      "source": [
        "### Initial Data Inspection Summary\n",
        "\n",
        "**df_dataset:**\n",
        "-   **Rows and Columns**: The `df_dataset` DataFrame contains 541,909 entries and 8 columns.\n",
        "-   **Data Types**: All columns are currently of `object` dtype, which suggests that some columns that should be numerical (e.g., `Quantity`, `UnitPrice`, `CustomerID`) or datetime (`InvoiceDate`) need type conversion.\n",
        "-   **Missing Values**:\n",
        "    -   `Description`: 540,884 non-null values out of 541,909, indicating ~1,025 missing values.\n",
        "    -   `CustomerID`: 433,909 non-null values out of 541,909, indicating ~108,000 missing values.\n",
        "-   **Data Anomalies/Special Characters**:\n",
        "    -   `StockCode`: Contains special characters like `ö` and `^` (e.g., `ö84406B^`).\n",
        "    -   `Quantity`: Contains special characters like `@` (e.g., `6@`).\n",
        "    -   `CustomerID`: Contains special characters like `&` and `#` (e.g., `&17850.0#`).\n",
        "    -   `Country`: Contains special characters like `X`, `x`, `Y`, `y`, and emojis (e.g., `XxYUnited Kingdom☺️`).\n",
        "    -   `InvoiceNo`: Contains numerical values and also appears to have 'object' type which might indicate non-numeric entries, possibly for cancelled orders (not explicitly seen in head, but common in such datasets).\n",
        "    -   `UnitPrice`: Appears to be a float but is of 'object' type, suggesting possible non-numeric entries or formatting issues.\n",
        "\n",
        "**df_cnn_train_data:**\n",
        "-   **Rows and Columns**: The `df_cnn_train_data` DataFrame is small, with 10 entries and 1 column.\n",
        "-   **Data Types**: The `StockCode` column is of `object` dtype.\n",
        "-   **Missing Values**: No missing values.\n",
        "-   **Data Anomalies/Special Characters**:\n",
        "    -   `StockCode`: Contains special characters like `ö` and `^` (e.g., `ö22384^`).\n",
        "\n",
        "**Next Steps based on Initial Inspection:**\n",
        "Based on these observations, significant data cleaning will be required for `df_dataset` to address incorrect data types, missing values, and special characters. `df_cnn_train_data` also requires cleaning of special characters in `StockCode`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7db8d7a"
      },
      "source": [
        "### Initial Data Inspection Summary\n",
        "\n",
        "**df_dataset:**\n",
        "-   **Rows and Columns**: The `df_dataset` DataFrame contains 541,909 entries and 8 columns.\n",
        "-   **Data Types**: All columns are currently of `object` dtype, which suggests that some columns that should be numerical (e.g., `Quantity`, `UnitPrice`, `CustomerID`) or datetime (`InvoiceDate`) need type conversion.\n",
        "-   **Missing Values**:\n",
        "    -   `Description`: 540,884 non-null values out of 541,909, indicating ~1,025 missing values.\n",
        "    -   `CustomerID`: 433,909 non-null values out of 541,909, indicating ~108,000 missing values.\n",
        "-   **Data Anomalies/Special Characters**:\n",
        "    -   `StockCode`: Contains special characters like `ö` and `^` (e.g., `ö84406B^`).\n",
        "    -   `Quantity`: Contains special characters like `@` (e.g., `6@`).\n",
        "    -   `CustomerID`: Contains special characters like `&` and `#` (e.g., `&17850.0#`).\n",
        "    -   `Country`: Contains special characters like `X`, `x`, `Y`, `y`, and emojis (e.g., `XxYUnited Kingdom☺️`).\n",
        "    -   `InvoiceNo`: Contains numerical values and also appears to have 'object' type which might indicate non-numeric entries, possibly for cancelled orders (not explicitly seen in head, but common in such datasets).\n",
        "    -   `UnitPrice`: Appears to be a float but is of 'object' type, suggesting possible non-numeric entries or formatting issues.\n",
        "\n",
        "**df_cnn_train_data:**\n",
        "-   **Rows and Columns**: The `df_cnn_train_data` DataFrame is small, with 10 entries and 1 column.\n",
        "-   **Data Types**: The `StockCode` column is of `object` dtype.\n",
        "-   **Missing Values**: No missing values.\n",
        "-   **Data Anomalies/Special Characters**:\n",
        "    -   `StockCode`: Contains special characters like `ö` and `^` (e.g., `ö22384^`).\n",
        "\n",
        "**Next Steps based on Initial Inspection:**\n",
        "Based on these observations, significant data cleaning will be required for `df_dataset` to address incorrect data types, missing values, and special characters. `df_cnn_train_data` also requires cleaning of special characters in `StockCode`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17a424f2"
      },
      "source": [
        "## Clean E-commerce Dataset\n",
        "\n",
        "### Subtask:\n",
        "Perform data cleaning on 'dataset.csv' (df_dataset), including identifying and removing duplicate entries, handling missing values, and standardizing data formats (e.g., product names, descriptions, categories, numerical columns, and date columns).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd74ec08"
      },
      "source": [
        "**Reasoning**:\n",
        "To begin the data cleaning process, I will first remove leading/trailing whitespace from all string columns in `df_dataset` as specified in the instructions. This is a common initial step for data standardization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d6ae15c"
      },
      "source": [
        "for col in df_dataset.select_dtypes(include='object').columns:\n",
        "    df_dataset[col] = df_dataset[col].astype(str).str.strip()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64814cbe"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the data cleaning instructions, I will clean the 'Quantity' column by removing non-numeric characters and then converting it to a numeric data type, coercing errors to NaN.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90c8be62",
        "outputId": "43011f6d-8fe4-49ce-d173-9f786ecb9d90"
      },
      "source": [
        "df_dataset['Quantity'] = df_dataset['Quantity'].astype(str).str.replace(r'[^\\d.-]', '', regex=True)\n",
        "df_dataset['Quantity'] = pd.to_numeric(df_dataset['Quantity'], errors='coerce')\n",
        "\n",
        "print(\"--- df_dataset Quantity Info after cleaning ---\")\n",
        "df_dataset['Quantity'].info()\n",
        "print(\"--- df_dataset Quantity head after cleaning ---\")\n",
        "print(df_dataset['Quantity'].head())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- df_dataset Quantity Info after cleaning ---\n",
            "<class 'pandas.core.series.Series'>\n",
            "RangeIndex: 541909 entries, 0 to 541908\n",
            "Series name: Quantity\n",
            "Non-Null Count   Dtype\n",
            "--------------   -----\n",
            "541909 non-null  int64\n",
            "dtypes: int64(1)\n",
            "memory usage: 4.1 MB\n",
            "--- df_dataset Quantity head after cleaning ---\n",
            "0    6\n",
            "1    6\n",
            "2    8\n",
            "3    6\n",
            "4    6\n",
            "Name: Quantity, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "818ae660"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the data cleaning instructions, I will clean the 'UnitPrice' column by converting it to a numeric data type, coercing errors to NaN.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7760859c",
        "outputId": "1b4889df-ab54-4023-f724-6301997e0939"
      },
      "source": [
        "df_dataset['UnitPrice'] = pd.to_numeric(df_dataset['UnitPrice'], errors='coerce')\n",
        "\n",
        "print(\"---> df_dataset UnitPrice Info after cleaning ---\")\n",
        "df_dataset['UnitPrice'].info()\n",
        "print(\"---> df_dataset UnitPrice head after cleaning ---\")\n",
        "print(df_dataset['UnitPrice'].head())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---> df_dataset UnitPrice Info after cleaning ---\n",
            "<class 'pandas.core.series.Series'>\n",
            "RangeIndex: 541909 entries, 0 to 541908\n",
            "Series name: UnitPrice\n",
            "Non-Null Count   Dtype  \n",
            "--------------   -----  \n",
            "433290 non-null  float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 4.1 MB\n",
            "---> df_dataset UnitPrice head after cleaning ---\n",
            "0    2.55\n",
            "1    3.39\n",
            "2    2.75\n",
            "3    3.39\n",
            "4    3.39\n",
            "Name: UnitPrice, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73aa1611"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the data cleaning instructions, I will clean the 'CustomerID' column by removing non-numeric characters and converting it to a numeric data type, coercing errors to NaN.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c8402e4",
        "outputId": "de291f37-0d43-44fb-bb9e-4a459c9b77f5"
      },
      "source": [
        "df_dataset['CustomerID'] = df_dataset['CustomerID'].astype(str).str.replace(r'[^\\d.]', '', regex=True)\n",
        "df_dataset['CustomerID'] = pd.to_numeric(df_dataset['CustomerID'], errors='coerce')\n",
        "\n",
        "print(\"--- df_dataset CustomerID Info after cleaning ---\")\n",
        "df_dataset['CustomerID'].info()\n",
        "print(\"--- df_dataset CustomerID head after cleaning ---\")\n",
        "print(df_dataset['CustomerID'].head())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- df_dataset CustomerID Info after cleaning ---\n",
            "<class 'pandas.core.series.Series'>\n",
            "RangeIndex: 541909 entries, 0 to 541908\n",
            "Series name: CustomerID\n",
            "Non-Null Count   Dtype  \n",
            "--------------   -----  \n",
            "406829 non-null  float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 4.1 MB\n",
            "--- df_dataset CustomerID head after cleaning ---\n",
            "0    17850.0\n",
            "1    17850.0\n",
            "2    17850.0\n",
            "3    17850.0\n",
            "4    17850.0\n",
            "Name: CustomerID, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a75aff48"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the data cleaning instructions, I will convert the 'InvoiceDate' column to a datetime data type to enable time-based analysis.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f616bfa2",
        "outputId": "7aa4f8f1-0da3-4589-f1eb-be733139655d"
      },
      "source": [
        "df_dataset['InvoiceDate'] = pd.to_datetime(df_dataset['InvoiceDate'], errors='coerce')\n",
        "\n",
        "print(\"--- df_dataset InvoiceDate Info after cleaning ---\")\n",
        "df_dataset['InvoiceDate'].info()\n",
        "print(\"--- df_dataset InvoiceDate head after cleaning ---\")\n",
        "print(df_dataset['InvoiceDate'].head())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- df_dataset InvoiceDate Info after cleaning ---\n",
            "<class 'pandas.core.series.Series'>\n",
            "RangeIndex: 541909 entries, 0 to 541908\n",
            "Series name: InvoiceDate\n",
            "Non-Null Count   Dtype         \n",
            "--------------   -----         \n",
            "541909 non-null  datetime64[ns]\n",
            "dtypes: datetime64[ns](1)\n",
            "memory usage: 4.1 MB\n",
            "--- df_dataset InvoiceDate head after cleaning ---\n",
            "0   2010-12-01 08:26:00\n",
            "1   2010-12-01 08:26:00\n",
            "2   2010-12-01 08:26:00\n",
            "3   2010-12-01 08:26:00\n",
            "4   2010-12-01 08:26:00\n",
            "Name: InvoiceDate, dtype: datetime64[ns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75bb975e"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the data cleaning instructions, I will clean the 'StockCode' column by removing special characters using regular expressions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "081e40d0",
        "outputId": "0ed77f52-6184-41c9-ea5d-b1081948c7df"
      },
      "source": [
        "df_dataset['StockCode'] = df_dataset['StockCode'].astype(str).str.replace(r'[^a-zA-Z0-9]', '', regex=True)\n",
        "df_cnn_train_data['StockCode'] = df_cnn_train_data['StockCode'].astype(str).str.replace(r'[^a-zA-Z0-9]', '', regex=True)\n",
        "\n",
        "print(\"--- df_dataset StockCode head after cleaning ---\")\n",
        "print(df_dataset['StockCode'].head())\n",
        "print(\"\\n--- df_cnn_train_data StockCode head after cleaning ---\")\n",
        "print(df_cnn_train_data['StockCode'].head())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- df_dataset StockCode head after cleaning ---\n",
            "0    85123A\n",
            "1     71053\n",
            "2    84406B\n",
            "3    84029G\n",
            "4    84029E\n",
            "Name: StockCode, dtype: object\n",
            "\n",
            "--- df_cnn_train_data StockCode head after cleaning ---\n",
            "0    22384\n",
            "1    22727\n",
            "2    22112\n",
            "3    23298\n",
            "4    20726\n",
            "Name: StockCode, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "293f4a73"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the data cleaning instructions, I will clean the 'Country' column by removing non-alphabetic characters and emojis, and then standardize the country names. I will first use a regular expression to remove characters that are not letters or spaces, then use `replace` to standardize common variations of 'United Kingdom'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f4a32f6",
        "outputId": "a8caca2a-e252-4dc4-94b1-d4627adb54ba"
      },
      "source": [
        "df_dataset['Country'] = df_dataset['Country'].astype(str).str.replace(r'[^a-zA-Z\\s]', '', regex=True)\n",
        "df_dataset['Country'] = df_dataset['Country'].str.replace('United Kingdom', 'United Kingdom', regex=False).str.strip()\n",
        "\n",
        "print(\"--- df_dataset Country head after cleaning ---\")\n",
        "print(df_dataset['Country'].head())\n",
        "print(\"\\n--- Unique countries after cleaning ---\")\n",
        "print(df_dataset['Country'].unique())\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- df_dataset Country head after cleaning ---\n",
            "0    XxYUnited Kingdom\n",
            "1       United Kingdom\n",
            "2    XxYUnited Kingdom\n",
            "3       United Kingdom\n",
            "4       United Kingdom\n",
            "Name: Country, dtype: object\n",
            "\n",
            "--- Unique countries after cleaning ---\n",
            "['XxYUnited Kingdom' 'United Kingdom' 'France' 'XxYFrance' 'XxYAustralia'\n",
            " 'Australia' 'XxYNetherlands' 'Netherlands' 'XxYGermany' 'Germany'\n",
            " 'Norway' 'XxYNorway' 'XxYEIRE' 'EIRE' 'XxYSwitzerland' 'Switzerland'\n",
            " 'Spain' 'XxYSpain' 'Poland' 'XxYPoland' 'Portugal' 'XxYPortugal' 'Italy'\n",
            " 'XxYItaly' 'Belgium' 'XxYBelgium' 'Lithuania' 'XxYLithuania' 'Japan'\n",
            " 'XxYJapan' 'XxYIceland' 'Iceland' 'XxYChannel Islands' 'Channel Islands'\n",
            " 'XxYDenmark' 'Denmark' 'XxYCyprus' 'Cyprus' 'XxYSweden' 'XxYAustria'\n",
            " 'Israel' 'XxYIsrael' 'Finland' 'XxYFinland' 'Austria' 'Sweden'\n",
            " 'XxYBahrain' 'Greece' 'XxYGreece' 'Hong Kong' 'XxYHong Kong'\n",
            " 'XxYSingapore' 'Singapore' 'XxYLebanon' 'Lebanon' 'United Arab Emirates'\n",
            " 'XxYUnited Arab Emirates' 'XxYSaudi Arabia' 'Saudi Arabia'\n",
            " 'Czech Republic' 'XxYCzech Republic' 'XxYCanada' 'Canada' 'Unspecified'\n",
            " 'XxYUnspecified' 'XxYBrazil' 'Brazil' 'XxYUSA' 'USA' 'European Community'\n",
            " 'XxYEuropean Community' 'Bahrain' 'Malta' 'XxYMalta' 'RSA' 'XxYRSA']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "672bf293"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to clean the 'Country' column did not fully remove the 'XxY' prefixes because 'X', 'x', 'Y', 'y' are considered alphabetic characters. To accurately follow the instruction to remove these specific characters along with other non-alphabetic characters and emojis, I will apply a multi-step cleaning process: first, explicitly remove `X`, `x`, `Y`, `y` characters, then remove any other non-alphabetic characters and emojis, and finally, standardize spacing and apply title casing for consistency.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92350411",
        "outputId": "ecad603b-e280-469c-81f6-7c0c6e644e94"
      },
      "source": [
        "df_dataset['Country'] = df_dataset['Country'].astype(str).str.replace(r'[XxYy]', '', regex=True)\n",
        "\n",
        "df_dataset['Country'] = df_dataset['Country'].str.replace(r'[^a-zA-Z\\s]', '', regex=True)\n",
        "\n",
        "df_dataset['Country'] = df_dataset['Country'].str.strip()\n",
        "df_dataset['Country'] = df_dataset['Country'].str.replace(r'\\s+', ' ', regex=True)\n",
        "\n",
        "df_dataset['Country'] = df_dataset['Country'].str.title()\n",
        "\n",
        "print(\"--- df_dataset Country head after cleaning ---\")\n",
        "print(df_dataset['Country'].head())\n",
        "print(\"\\n--- Unique countries after cleaning ---\")\n",
        "print(df_dataset['Country'].unique())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- df_dataset Country head after cleaning ---\n",
            "0    United Kingdom\n",
            "1    United Kingdom\n",
            "2    United Kingdom\n",
            "3    United Kingdom\n",
            "4    United Kingdom\n",
            "Name: Country, dtype: object\n",
            "\n",
            "--- Unique countries after cleaning ---\n",
            "['United Kingdom' 'France' 'Australia' 'Netherlands' 'German' 'Norwa'\n",
            " 'Eire' 'Switzerland' 'Spain' 'Poland' 'Portugal' 'Ital' 'Belgium'\n",
            " 'Lithuania' 'Japan' 'Iceland' 'Channel Islands' 'Denmark' 'Cprus'\n",
            " 'Sweden' 'Austria' 'Israel' 'Finland' 'Bahrain' 'Greece' 'Hong Kong'\n",
            " 'Singapore' 'Lebanon' 'United Arab Emirates' 'Saudi Arabia'\n",
            " 'Czech Republic' 'Canada' 'Unspecified' 'Brazil' 'Usa'\n",
            " 'European Communit' 'Malta' 'Rsa']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d01de0d"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the data cleaning instructions, I will address missing values by filling missing 'Description' values with 'Unknown Product' as a placeholder.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2984663",
        "outputId": "0078efd1-7388-40bc-8846-d57e17098f07"
      },
      "source": [
        "df_dataset['Description'].fillna('Unknown Product', inplace=True)\n",
        "\n",
        "print(\"--- df_dataset Description Info after handling missing values ---\")\n",
        "df_dataset['Description'].info()\n",
        "print(\"--- df_dataset Description head after handling missing values ---\")\n",
        "print(df_dataset['Description'].head())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- df_dataset Description Info after handling missing values ---\n",
            "<class 'pandas.core.series.Series'>\n",
            "RangeIndex: 541909 entries, 0 to 541908\n",
            "Series name: Description\n",
            "Non-Null Count   Dtype \n",
            "--------------   ----- \n",
            "541909 non-null  object\n",
            "dtypes: object(1)\n",
            "memory usage: 4.1+ MB\n",
            "--- df_dataset Description head after handling missing values ---\n",
            "0      WHITE HANGING HEART T-LIGHT HOLDER\n",
            "1                     WHITE METAL LANTERN\n",
            "2          CREAM CUPID HEARTS COAT HANGER\n",
            "3    $KNITTED UNION FLAG HOT WATER BOTTLE\n",
            "4         $RED WOOLLY HOTTIE WHITE HEART.\n",
            "Name: Description, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4206370445.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_dataset['Description'].fillna('Unknown Product', inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1a8d438"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code produced a FutureWarning related to `inplace=True` when modifying a DataFrame slice. To address this and ensure future compatibility, I will re-write the `fillna` operation by directly assigning the result back to the 'Description' column, which is the recommended practice.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83e9fb23",
        "outputId": "9d9cbdf0-521b-45f7-a267-478602e3d16b"
      },
      "source": [
        "df_dataset['Description'] = df_dataset['Description'].fillna('Unknown Product')\n",
        "\n",
        "print(\"--- df_dataset Description Info after handling missing values ---\")\n",
        "df_dataset['Description'].info()\n",
        "print(\"--- df_dataset Description head after handling missing values ---\")\n",
        "print(df_dataset['Description'].head())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- df_dataset Description Info after handling missing values ---\n",
            "<class 'pandas.core.series.Series'>\n",
            "RangeIndex: 541909 entries, 0 to 541908\n",
            "Series name: Description\n",
            "Non-Null Count   Dtype \n",
            "--------------   ----- \n",
            "541909 non-null  object\n",
            "dtypes: object(1)\n",
            "memory usage: 4.1+ MB\n",
            "--- df_dataset Description head after handling missing values ---\n",
            "0      WHITE HANGING HEART T-LIGHT HOLDER\n",
            "1                     WHITE METAL LANTERN\n",
            "2          CREAM CUPID HEARTS COAT HANGER\n",
            "3    $KNITTED UNION FLAG HOT WATER BOTTLE\n",
            "4         $RED WOOLLY HOTTIE WHITE HEART.\n",
            "Name: Description, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37f84610"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the data cleaning instructions, I will address missing values in the 'CustomerID' column. Given that `CustomerID` is essential for personalized recommendations, and imputing it would create artificial users, the most appropriate strategy is to remove rows where `CustomerID` is missing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82f219b1",
        "outputId": "f61329ad-75eb-4b68-c5d5-943dbfdf5194"
      },
      "source": [
        "df_dataset.dropna(subset=['CustomerID'], inplace=True)\n",
        "\n",
        "print(\"--- df_dataset CustomerID Info after handling missing values ---\")\n",
        "df_dataset['CustomerID'].info()\n",
        "print(\"--- df_dataset head after handling missing CustomerID ---\")\n",
        "print(df_dataset.head())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- df_dataset CustomerID Info after handling missing values ---\n",
            "<class 'pandas.core.series.Series'>\n",
            "Index: 406829 entries, 0 to 541908\n",
            "Series name: CustomerID\n",
            "Non-Null Count   Dtype  \n",
            "--------------   -----  \n",
            "406829 non-null  float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 6.2 MB\n",
            "--- df_dataset head after handling missing CustomerID ---\n",
            "  InvoiceNo StockCode                           Description  Quantity  \\\n",
            "0    536365    85123A    WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
            "1    536365     71053                   WHITE METAL LANTERN         6   \n",
            "2    536365    84406B        CREAM CUPID HEARTS COAT HANGER         8   \n",
            "3    536365    84029G  $KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
            "4    536365    84029E       $RED WOOLLY HOTTIE WHITE HEART.         6   \n",
            "\n",
            "          InvoiceDate  UnitPrice  CustomerID         Country  \n",
            "0 2010-12-01 08:26:00       2.55     17850.0  United Kingdom  \n",
            "1 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
            "2 2010-12-01 08:26:00       2.75     17850.0  United Kingdom  \n",
            "3 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
            "4 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b807a484"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the data cleaning instructions, the final step for `df_dataset` is to identify and remove any duplicate rows across all columns to ensure data integrity and uniqueness.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d15e668",
        "outputId": "ce5871da-5eb6-4001-8a67-a81a64b91525"
      },
      "source": [
        "initial_rows = df_dataset.shape[0]\n",
        "df_dataset.drop_duplicates(inplace=True)\n",
        "final_rows = df_dataset.shape[0]\n",
        "duplicates_removed = initial_rows - final_rows\n",
        "\n",
        "print(f\"--- Duplicate Rows Removed: {duplicates_removed} ---\")\n",
        "print(\"--- df_dataset Info after removing duplicates ---\")\n",
        "df_dataset.info()\n",
        "print(\"--- df_dataset head after removing duplicates ---\")\n",
        "print(df_dataset.head())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Duplicate Rows Removed: 1087 ---\n",
            "--- df_dataset Info after removing duplicates ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 405742 entries, 0 to 541908\n",
            "Data columns (total 8 columns):\n",
            " #   Column       Non-Null Count   Dtype         \n",
            "---  ------       --------------   -----         \n",
            " 0   InvoiceNo    405742 non-null  object        \n",
            " 1   StockCode    405742 non-null  object        \n",
            " 2   Description  405742 non-null  object        \n",
            " 3   Quantity     405742 non-null  int64         \n",
            " 4   InvoiceDate  405742 non-null  datetime64[ns]\n",
            " 5   UnitPrice    324104 non-null  float64       \n",
            " 6   CustomerID   405742 non-null  float64       \n",
            " 7   Country      405742 non-null  object        \n",
            "dtypes: datetime64[ns](1), float64(2), int64(1), object(4)\n",
            "memory usage: 27.9+ MB\n",
            "--- df_dataset head after removing duplicates ---\n",
            "  InvoiceNo StockCode                           Description  Quantity  \\\n",
            "0    536365    85123A    WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
            "1    536365     71053                   WHITE METAL LANTERN         6   \n",
            "2    536365    84406B        CREAM CUPID HEARTS COAT HANGER         8   \n",
            "3    536365    84029G  $KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
            "4    536365    84029E       $RED WOOLLY HOTTIE WHITE HEART.         6   \n",
            "\n",
            "          InvoiceDate  UnitPrice  CustomerID         Country  \n",
            "0 2010-12-01 08:26:00       2.55     17850.0  United Kingdom  \n",
            "1 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
            "2 2010-12-01 08:26:00       2.75     17850.0  United Kingdom  \n",
            "3 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
            "4 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee5e6eb9"
      },
      "source": [
        "# Task\n",
        "Initialize Pinecone by installing the `pinecone-client` library and then using your actual Pinecone API key and environment to configure the Pinecone client."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a10609e"
      },
      "source": [
        "## Initialize Pinecone\n",
        "\n",
        "### Subtask:\n",
        "Install the `pinecone-client` library and initialize the Pinecone client with your API key and environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "258ba1da",
        "outputId": "45f58220-d938-4afe-da3f-657189332263"
      },
      "source": [
        "!pip install pinecone\n",
        "print(\"pinecone library installation initiated.\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pinecone in /usr/local/lib/python3.12/dist-packages (8.0.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2025.11.12)\n",
            "Requirement already satisfied: orjson>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from pinecone) (3.11.4)\n",
            "Requirement already satisfied: pinecone-plugin-assistant<4.0.0,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from pinecone) (3.0.1)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.1.0,>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.12/dist-packages (from pinecone) (4.15.0)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2.5.0)\n",
            "Requirement already satisfied: packaging<25.0,>=24.2 in /usr/local/lib/python3.12/dist-packages (from pinecone-plugin-assistant<4.0.0,>=3.0.1->pinecone) (24.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /usr/local/lib/python3.12/dist-packages (from pinecone-plugin-assistant<4.0.0,>=3.0.1->pinecone) (2.32.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<4.0.0,>=3.0.1->pinecone) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<4.0.0,>=3.0.1->pinecone) (3.11)\n",
            "pinecone library installation initiated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11e7bbdb",
        "outputId": "ee6d3f56-5b13-41f7-f033-2cc56a3ca91c"
      },
      "source": [
        "from pinecone import Pinecone\n",
        "\n",
        "# Initialize Pinecone with your actual API key and environment\n",
        "pinecone_api_key = 'pcsk_2R7pte_GNVPJiRfCNsH93RQRaJh1REjCEL7xQUvSrdaCHJ3QgYJNE8EyS2Pt9PabSBX1NC'\n",
        "pinecone_environment = 'gcp-starter' # Using a common placeholder for the environment\n",
        "\n",
        "pinecone = Pinecone(api_key=pinecone_api_key, environment=pinecone_environment)\n",
        "\n",
        "print(\"Pinecone client initialized.\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pinecone client initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d361607"
      },
      "source": [
        "## Create Pinecone Index\n",
        "\n",
        "### Subtask:\n",
        "Create a new Pinecone index or connect to an existing one, defining the index name, dimension, and metric type suitable for product vector similarity search.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4395a8cd"
      },
      "source": [
        "### Pinecone Index Parameters\n",
        "\n",
        "To create or connect to a Pinecone index, we need to define the following parameters:\n",
        "\n",
        "1.  **Index Name**: `ecommerce-product-vectors` will be used as a descriptive name for our product vector index.\n",
        "2.  **Dimension**: While we haven't selected an embedding model yet, a common dimension for many general-purpose embedding models (like those from OpenAI, Sentence Transformers, etc.) is 1536 or 768. For now, I will use **1536** as a placeholder, which can be adjusted later once a specific embedding model is chosen. If we were to use a model like `text-embedding-ada-002`, the dimension would be 1536.\n",
        "3.  **Metric Type**: For product recommendation, **cosine similarity** is a widely used and effective metric. It measures the cosine of the angle between two vectors, indicating how similar their orientations are. `euclidean` (Euclidean distance) or `dotproduct` could also be options, but `cosine` often performs well for semantic similarity tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "246dcdbb"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the Pinecone client is initialized and the index parameters are defined, I will write the code to check for the existence of the specified Pinecone index and either connect to it or create a new one, as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e156cf5b",
        "outputId": "ecfc3fe1-af28-4848-d5bc-7ecf38865d02"
      },
      "source": [
        "from pinecone import Pinecone, ServerlessSpec\n",
        "import time\n",
        "\n",
        "# ⚠️ SECURITY WARNING: Never hardcode your API key in shared code!\n",
        "# Use os.environ.get('PINECONE_API_KEY') instead.\n",
        "pinecone_api_key = 'pcsk_2R7pte_GNVPJiRfCNsH93RQRaJh1REjCEL7xQUvSrdaCHJ3QgYJNE8EyS2Pt9PabSBX1NC'\n",
        "\n",
        "# 1. Initialize Pinecone\n",
        "pc = Pinecone(api_key=pinecone_api_key)\n",
        "\n",
        "index_name = 'ecommerce-product-vectors'\n",
        "dimension = 1536\n",
        "metric_type = 'cosine'\n",
        "\n",
        "# 2. Correctly check existing indexes\n",
        "# list_indexes() returns an object, so we must extract the names\n",
        "existing_indexes = [index_info['name'] for index_info in pc.list_indexes()]\n",
        "\n",
        "if index_name not in existing_indexes:\n",
        "    print(f\"Creating new index '{index_name}'...\")\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=dimension,\n",
        "        metric=metric_type,\n",
        "        # 'us-east-1' is the most standard region for AWS Free Tier Serverless\n",
        "        spec=ServerlessSpec(cloud='aws', region='us-east-1')\n",
        "    )\n",
        "    # Wait a moment for the index to initialize\n",
        "    while not pc.describe_index(index_name).status['ready']:\n",
        "        time.sleep(1)\n",
        "    print(f\"Index '{index_name}' created successfully.\")\n",
        "else:\n",
        "    print(f\"Index '{index_name}' already exists. Connecting to it...\")\n",
        "\n",
        "# 3. Connect to the index\n",
        "index = pc.Index(index_name)\n",
        "\n",
        "print(f\"Successfully connected to index '{index_name}'.\")\n",
        "print(\"Index stats:\")\n",
        "print(index.describe_index_stats())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index 'ecommerce-product-vectors' already exists. Connecting to it...\n",
            "Successfully connected to index 'ecommerce-product-vectors'.\n",
            "Index stats:\n",
            "{'_response_info': {'raw_headers': {'connection': 'keep-alive',\n",
            "                                    'content-length': '151',\n",
            "                                    'content-type': 'application/json',\n",
            "                                    'date': 'Thu, 11 Dec 2025 15:38:01 GMT',\n",
            "                                    'grpc-status': '0',\n",
            "                                    'server': 'envoy',\n",
            "                                    'x-envoy-upstream-service-time': '31',\n",
            "                                    'x-pinecone-request-id': '7463519594218830597',\n",
            "                                    'x-pinecone-request-latency-ms': '31'}},\n",
            " 'dimension': 1536,\n",
            " 'index_fullness': 0.0,\n",
            " 'memoryFullness': 0.0,\n",
            " 'metric': 'cosine',\n",
            " 'namespaces': {},\n",
            " 'storageFullness': 0.0,\n",
            " 'total_vector_count': 0,\n",
            " 'vector_type': 'dense'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93fbaf61"
      },
      "source": [
        "## Define Product Vector Schema\n",
        "\n",
        "### Subtask:\n",
        "Define the schema and metadata structure for the product vectors that will be stored in the Pinecone index, ensuring it aligns with the e-commerce dataset's features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0ab2d1b"
      },
      "source": [
        "### Product Vector Metadata Schema for Pinecone\n",
        "\n",
        "Based on the `df_dataset` and the requirements for product recommendation and search, the following metadata fields will be included alongside each product's vector embedding in the Pinecone index:\n",
        "\n",
        "1.  **`StockCode`**:\n",
        "    *   **Rationale**: This is a unique identifier for each product. It is crucial for retrieving specific product details from the main `df_dataset` once a vector search returns relevant product vectors. It allows for direct lookup and linking back to the original product information.\n",
        "    *   **Suitability**: The `StockCode` has already been cleaned to remove special characters and is suitable for direct storage as a string. It will serve as a primary key for product identification.\n",
        "\n",
        "2.  **`Description`**:\n",
        "    *   **Rationale**: The product description provides rich textual information about the product. While the vector itself will capture semantic meaning from the description, storing the original description allows for human-readable display in recommendation results and can be used for keyword-based filtering or display in the frontend.\n",
        "    *   **Suitability**: The `Description` column has been handled for missing values (filled with 'Unknown Product') and is suitable for direct storage as a string. Further text cleaning (e.g., lowercasing, removing extra spaces) might be considered if exact string matching is needed for filtering, but for display, the current state is sufficient.\n",
        "\n",
        "3.  **`Country`**:\n",
        "    *   **Rationale**: The `Country` field indicates the origin or target market for a product, which can be valuable for filtering recommendations by region or for understanding geographical sales patterns. For example, a user might want to filter products available only in their country.\n",
        "    *   **Suitability**: The `Country` column has been cleaned and standardized to remove special characters and normalize names (e.g., 'United Kingdom'). It is suitable for storage as a string and can be directly used for filtering or grouping product recommendations.\n",
        "\n",
        "4.  **`UnitPrice`**:\n",
        "    *   **Rationale**: The unit price is a critical attribute for product comparison and filtering (e.g., filtering products within a certain price range). Including it in metadata allows for dynamic price-based filtering post-vector search without needing to join with the original dataset.\n",
        "    *   **Suitability**: The `UnitPrice` has been converted to a numeric type (float64) and is suitable for direct storage. Missing values in `UnitPrice` were coerced to `NaN` during cleaning; these can be handled during indexing (e.g., excluded or given a default value) if products without a price should still be searchable or filterable.\n",
        "\n",
        "5.  **`Quantity`**:\n",
        "    *   **Rationale**: The quantity of items in an invoice line can be an indicator of popularity or bulk purchase behavior. While not directly for filtering products in a recommendation system, it might be useful for aggregation or as an additional display metric.\n",
        "    *   **Suitability**: The `Quantity` has been cleaned and converted to an integer type. It is suitable for direct storage.\n",
        "\n",
        "\n",
        "These fields are selected to provide a balance between essential identification (`StockCode`), descriptive content (`Description`), contextual information (`Country`), and quantifiable attributes (`UnitPrice`, `Quantity`), enabling flexible search, filtering, and display capabilities for the product recommendation service."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e864a34"
      },
      "source": [
        "## Prepare Database for Embeddings\n",
        "\n",
        "### Subtask:\n",
        "Prepare the database for storing product embeddings, which involves defining how product information will be converted into vector representations suitable for Pinecone.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a29f5526"
      },
      "source": [
        "### 1. Identify Columns for Embeddings\n",
        "\n",
        "For generating product embeddings, the following columns from `df_dataset` are relevant:\n",
        "\n",
        "*   **`Description`**: This is the most crucial column as it contains detailed textual information about the product. Semantic similarity will largely depend on the quality of this text.\n",
        "*   **`StockCode`**: While primarily an identifier, if used in combination with the description, it might provide a unique context. However, given its format after cleaning (alphanumeric only), its direct semantic contribution might be limited unless mapped to specific product categories or types.\n",
        "*   **`Country`**: This column indicates the country of origin or sale. While not directly describing the product, it could be a valuable piece of metadata to filter or refine recommendations based on regional preferences. For embeddings, it might be less directly useful than `Description`.\n",
        "\n",
        "Therefore, `Description` will be the primary source for generating semantic embeddings, and `StockCode` and `Country` can serve as valuable metadata fields for filtering and enriching search results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f5e4149"
      },
      "source": [
        "### 2. Further Text Cleaning and Preprocessing\n",
        "\n",
        "Based on the current state of the `df_dataset` after initial cleaning, some further text cleaning and preprocessing steps are beneficial before generating embeddings:\n",
        "\n",
        "*   **`Description`**: While `str.strip()` was applied, the `Description` column still contains some special characters (e.g., '$', '.') and inconsistent casing. For optimal embedding quality, these should be addressed:\n",
        "    *   **Lowercasing**: Convert all text to lowercase to treat words like \"Holder\" and \"holder\" as the same.\n",
        "    *   **Punctuation Removal**: Remove remaining punctuation marks that might not contribute to semantic meaning.\n",
        "    *   **Special Character Removal**: Ensure any lingering non-alphanumeric characters (beyond standard text punctuation) are removed.\n",
        "    *   **Redundant Spaces**: Consolidate multiple spaces into a single space.\n",
        "\n",
        "*   **`StockCode`**: This column has been cleaned to be purely alphanumeric. For embedding purposes, it's generally best used as a unique identifier or metadata. Combining it directly with `Description` for embedding might introduce noise unless there's a clear semantic link in the `StockCode` itself. It will be kept as is for now and considered as metadata.\n",
        "\n",
        "*   **`Country`**: This column has been cleaned to be in title case with special characters removed. It is suitable for use as metadata directly. For embedding, it would likely be handled separately (e.g., one-hot encoded or embedded individually) rather than combined directly with product descriptions, as its semantic context is different.\n",
        "\n",
        "**Conclusion for Preprocessing**: The primary focus for further cleaning will be on the `Description` column to ensure it is as clean and normalized as possible for robust embedding generation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "534df5aa"
      },
      "source": [
        "**Reasoning**:\n",
        "To ensure the `Description` column is clean and ready for embedding generation, I will apply the identified preprocessing steps: lowercasing, removing special characters and punctuation, and consolidating spaces.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92bf65f3",
        "outputId": "200698fa-1294-4a9a-d95e-14988133e7a4"
      },
      "source": [
        "import re\n",
        "\n",
        "# Lowercasing, removing special characters/punctuation, and consolidating spaces\n",
        "df_dataset['Description'] = df_dataset['Description'].astype(str).str.lower()\n",
        "df_dataset['Description'] = df_dataset['Description'].apply(lambda x: re.sub(r'[^a-z0-9\\s]', '', x))\n",
        "df_dataset['Description'] = df_dataset['Description'].apply(lambda x: re.sub(r'\\s+', ' ', x)).str.strip()\n",
        "\n",
        "print(\"--- df_dataset Description head after comprehensive cleaning ---\")\n",
        "print(df_dataset['Description'].head())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- df_dataset Description head after comprehensive cleaning ---\n",
            "0      white hanging heart tlight holder\n",
            "1                    white metal lantern\n",
            "2         cream cupid hearts coat hanger\n",
            "3    knitted union flag hot water bottle\n",
            "4          red woolly hottie white heart\n",
            "Name: Description, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87790228",
        "outputId": "734d3feb-488b-459f-968a-5ff13580bc59"
      },
      "source": [
        "print(\"--- Verified df_dataset Description column (head) ---\")\n",
        "print(df_dataset['Description'].head())\n",
        "\n",
        "print(\"\\n--- Verified df_dataset Info (after all cleaning) ---\")\n",
        "df_dataset.info()\n",
        "\n",
        "print(\"\\n--- Verified df_dataset Head (after all cleaning) ---\")\n",
        "print(df_dataset.head())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Verified df_dataset Description column (head) ---\n",
            "0      white hanging heart tlight holder\n",
            "1                    white metal lantern\n",
            "2         cream cupid hearts coat hanger\n",
            "3    knitted union flag hot water bottle\n",
            "4          red woolly hottie white heart\n",
            "Name: Description, dtype: object\n",
            "\n",
            "--- Verified df_dataset Info (after all cleaning) ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 405742 entries, 0 to 541908\n",
            "Data columns (total 8 columns):\n",
            " #   Column       Non-Null Count   Dtype         \n",
            "---  ------       --------------   -----         \n",
            " 0   InvoiceNo    405742 non-null  object        \n",
            " 1   StockCode    405742 non-null  object        \n",
            " 2   Description  405742 non-null  object        \n",
            " 3   Quantity     405742 non-null  int64         \n",
            " 4   InvoiceDate  405742 non-null  datetime64[ns]\n",
            " 5   UnitPrice    324104 non-null  float64       \n",
            " 6   CustomerID   405742 non-null  float64       \n",
            " 7   Country      405742 non-null  object        \n",
            "dtypes: datetime64[ns](1), float64(2), int64(1), object(4)\n",
            "memory usage: 27.9+ MB\n",
            "\n",
            "--- Verified df_dataset Head (after all cleaning) ---\n",
            "  InvoiceNo StockCode                          Description  Quantity  \\\n",
            "0    536365    85123A    white hanging heart tlight holder         6   \n",
            "1    536365     71053                  white metal lantern         6   \n",
            "2    536365    84406B       cream cupid hearts coat hanger         8   \n",
            "3    536365    84029G  knitted union flag hot water bottle         6   \n",
            "4    536365    84029E        red woolly hottie white heart         6   \n",
            "\n",
            "          InvoiceDate  UnitPrice  CustomerID         Country  \n",
            "0 2010-12-01 08:26:00       2.55     17850.0  United Kingdom  \n",
            "1 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
            "2 2010-12-01 08:26:00       2.75     17850.0  United Kingdom  \n",
            "3 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
            "4 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dc98ad9"
      },
      "source": [
        "## Select Embedding Model\n",
        "\n",
        "### Subtask:\n",
        "Identify and select an appropriate pre-trained embedding model (e.g., a Sentence Transformer model) suitable for generating semantic vectors from product descriptions, considering factors like embedding dimension and performance on e-commerce text.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9144ef9d"
      },
      "source": [
        "### Selected Embedding Model: `text-embedding-ada-002` (OpenAI)\n",
        "\n",
        "**Justification for Selection:**\n",
        "\n",
        "1.  **Embedding Dimension Match (1536)**: Our Pinecone index has been configured with a dimension of 1536. The `text-embedding-ada-002` model from OpenAI natively produces embeddings of this exact dimension, ensuring direct compatibility without any need for dimensionality reduction, padding, or re-configuring the Pinecone index.\n",
        "\n",
        "2.  **High Performance for Semantic Similarity**: This model is a state-of-the-art embedding model known for its strong performance in various semantic search and text similarity tasks. It excels at capturing the nuanced semantic meaning of text, which is crucial for accurate product recommendations based on descriptions.\n",
        "\n",
        "3.  **Suitability for E-commerce Text**: `text-embedding-ada-002` has been trained on a vast corpus of text, making it robust for understanding diverse vocabulary and concepts present in e-commerce product descriptions, even with slight variations or informal language. It effectively captures relationships between different products.\n",
        "\n",
        "4.  **Industry Standard and Ecosystem**: OpenAI embeddings are widely adopted in industry, benefiting from continuous improvements and a robust support ecosystem. This reduces potential issues during integration and scaling.\n",
        "\n",
        "**Required Library and Model Name:**\n",
        "\n",
        "*   **Library**: `openai` (Python client library for OpenAI API)\n",
        "*   **Model Name for API calls**: `text-embedding-ada-002`\n",
        "\n",
        "*Note: Using this model will require an OpenAI API key for authentication.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65f1e8b4"
      },
      "source": [
        "## Generate Embeddings\n",
        "\n",
        "### Subtask:\n",
        "Generate embeddings for each cleaned product description in `df_dataset` using the selected `text-embedding-ada-002` model, preparing the data for storage in the Pinecone index.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53cc723b"
      },
      "source": [
        "**Reasoning**:\n",
        "To generate embeddings for the product descriptions, I need to import the OpenAI client, set the API key, define an embedding function, and then apply it to the 'Description' column of `df_dataset`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1adf9435"
      },
      "source": [
        "# Task\n",
        "## Select Embedding Model (Gemini)\n",
        "\n",
        "### Subtask:\n",
        "Identify and select an appropriate Gemini embedding model suitable for generating semantic vectors from product descriptions, considering factors like embedding dimension and performance on e-commerce text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "886db8c5"
      },
      "source": [
        "## Select Embedding Model (Gemini)\n",
        "\n",
        "### Subtask:\n",
        "Identify and select an appropriate Gemini embedding model suitable for generating semantic vectors from product descriptions, considering factors like embedding dimension and performance on e-commerce text.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "498c7219"
      },
      "source": [
        "### Selected Embedding Model: `text-embedding-004` (Gemini)\n",
        "\n",
        "**Justification for Selection:**\n",
        "\n",
        "1.  **High Performance for Semantic Similarity**: The `text-embedding-004` model is a highly capable embedding model from Google's Gemini family, designed to produce high-quality semantic representations of text. It is well-suited for capturing the nuanced meaning in product descriptions, which is essential for accurate similarity searches and recommendations in an e-commerce context.\n",
        "\n",
        "2.  **Suitability for E-commerce Text**: Gemini models, especially `text-embedding-004`, have been trained on vast and diverse datasets, making them robust in understanding various types of text, including detailed product descriptions, features, and informal language often found in e-commerce. This ensures that the embeddings will effectively represent product attributes and enable discovery of semantically related items.\n",
        "\n",
        "3.  **Embedding Dimension**: `text-embedding-004` typically produces embeddings with a dimension of **768**. While our Pinecone index was initially set up with 1536, it's important to note that the dimension for Pinecone can be adjusted or a new index created to match the model's output. If we strictly need to maintain 1536, another model or method would be required. However, 768 is a common and effective dimension for many semantic tasks, offering a good balance between expressiveness and computational efficiency.\n",
        "\n",
        "**Required Library and Model Name:**\n",
        "\n",
        "*   **Library**: `google-generativeai` (Python client library for Google Gemini API)\n",
        "*   **Model Name for API calls**: `models/text-embedding-004` (or `text-embedding-004` depending on the client library version and usage pattern).\n",
        "\n",
        "*Note: Using this model will require a Google Cloud or Google AI Studio API key for authentication.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93945f95"
      },
      "source": [
        "**Reasoning**:\n",
        "To use the selected Gemini embedding model, the first step is to install the required Python client library, `google-generativeai`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48b89e17",
        "outputId": "17d9990b-b924-4b05-e829-c81a9de05ef9"
      },
      "source": [
        "!pip install -q google-generativeai\n",
        "print(\"Google Generative AI Python client library installation initiated.\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Generative AI Python client library installation initiated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "353c05f7"
      },
      "source": [
        "**Reasoning**:\n",
        "To generate embeddings using the Gemini model, I need to configure the Google Generative AI client with an API key. This step initializes the client, allowing subsequent calls to the embedding model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c2fd8d2",
        "outputId": "e7e7cb71-1e6c-4105-eb98-c6171bd5c740"
      },
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "# For demonstration purposes, replace 'YOUR_GOOGLE_API_KEY' with your actual key if not set as an environment variable.\n",
        "GOOGLE_API_KEY = 'AIzaSyB7OBr2kbcV-ecinTRvqnam48S3sf3ETkw' # Replace with your actual API key if not using env vars\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "print(\"Google Generative AI client configured.\")\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Generative AI client configured.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f316791"
      },
      "source": [
        "**Reasoning**:\n",
        "To generate embeddings for the 'Description' column, I will define a function that uses the configured Gemini model (`models/text-embedding-004`) to produce embeddings for each product description. I'll include a delay to manage potential rate limits and store the embeddings in a new column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "5af0120625204da8873678a9604b346f",
            "9a5d2eca84204f4f95bdff24f5bde223",
            "e855cfa6332f4c02ac4ff6bc1392fda2",
            "fd3cb9d571ee4a82a0f08ddf571776d6",
            "5f03847bf39643ffa8e655dae26c1708",
            "e34aacf387874ca38e528033580a8416",
            "f448a53169f444a6807808adf5de4bce",
            "b9ad4f0f83b74d228fe63829784ef023",
            "84f16e5b31c144fc800e50e95df597a2",
            "60e3840abbf0406cac910803e4401399",
            "d2a693afc81a4d738d4b40dc50ba8709"
          ]
        },
        "id": "8c100e04",
        "outputId": "39a44cba-e210-49f5-99ae-f47c3c2fd006"
      },
      "source": [
        "from tqdm.auto import tqdm\n",
        "import time\n",
        "\n",
        "# 1. Grab a small sample (TEST DATA ONLY)\n",
        "# We use .copy() to avoid SettingWithCopy warnings\n",
        "df_test = df_dataset.head(100).copy()\n",
        "\n",
        "# 2. Clean data (Remove empty descriptions in the test set)\n",
        "df_test = df_test[df_test['Description'].str.strip().astype(bool)]\n",
        "\n",
        "# 3. Settings\n",
        "batch_size = 50\n",
        "texts = df_test['Description'].tolist()\n",
        "embeddings = []\n",
        "\n",
        "print(f\"Starting TEST run for {len(texts)} items...\")\n",
        "\n",
        "# 4. Loop through the small test data\n",
        "for i in tqdm(range(0, len(texts), batch_size)):\n",
        "    batch = texts[i : i + batch_size]\n",
        "    try:\n",
        "        response = genai.embed_content(\n",
        "            model='models/text-embedding-004',\n",
        "            content=batch,\n",
        "            task_type=\"retrieval_document\"\n",
        "        )\n",
        "        embeddings.extend(response['embedding'])\n",
        "        time.sleep(0.5)\n",
        "    except Exception as e:\n",
        "        print(f\"Error at batch {i}: {e}\")\n",
        "        embeddings.extend([None] * len(batch))\n",
        "\n",
        "# 5. Assign back to the TEST dataframe\n",
        "df_test['Description_Embedding'] = embeddings\n",
        "\n",
        "print(\"✅ Test Complete! Check 'df_test' for results.\")\n",
        "print(df_test['Description_Embedding'].head())"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting TEST run for 100 items...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5af0120625204da8873678a9604b346f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Test Complete! Check 'df_test' for results.\n",
            "0    [-0.0014516105, -0.022812035, -0.005761458, 0....\n",
            "1    [-0.013041349, -0.030472137, 0.005665489, 0.00...\n",
            "2    [-0.0044767363, 0.021094194, 7.9084035e-05, 0....\n",
            "3    [-0.005095341, 0.0054738144, 0.00080697204, 0....\n",
            "4    [-0.007376628, 0.014837482, -0.009179558, 0.01...\n",
            "Name: Description_Embedding, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7759c460"
      },
      "source": [
        "# Task\n",
        "Generate embeddings for a sample of 5000 product descriptions from `df_dataset` using the `models/text-embedding-004` Gemini model. Implement concurrent processing with a `BATCH_SIZE` of 50, `MAX_WORKERS` of 2, and `MAX_RETRIES` of 3 to handle API calls efficiently and robustly. Store these embeddings in a new column named 'Description_Embedding' within the `df_sample` DataFrame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "034edc50"
      },
      "source": [
        "## Generate Embeddings for a Sample with Concurrent Processing and Retries\n",
        "\n",
        "### Subtask:\n",
        "Generate embeddings for a sample of 5000 rows from `df_dataset` (after filtering out empty descriptions) using the `models/text-embedding-004` Gemini model. This will involve using `concurrent.futures` for parallel processing with a `BATCH_SIZE` of 50, `MAX_WORKERS` of 2, and `MAX_RETRIES` of 3, as specified. The embeddings will be stored in a new 'Description_Embedding' column in `df_sample`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ace9775"
      },
      "source": [
        "**Reasoning**:\n",
        "To begin the concurrent embedding generation process, I need to import the `ThreadPoolExecutor` for parallel processing and define the constants for `SAMPLE_SIZE`, `BATCH_SIZE`, `MAX_WORKERS`, and `MAX_RETRIES` as specified in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a9b66b1",
        "outputId": "bef6df1f-a3d5-4d8e-e2ea-f96f2766908e"
      },
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import time\n",
        "\n",
        "# Define constants\n",
        "SAMPLE_SIZE = 5000\n",
        "BATCH_SIZE = 50\n",
        "MAX_WORKERS = 2\n",
        "MAX_RETRIES = 3\n",
        "\n",
        "print(\"Constants for embedding generation defined.\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Constants for embedding generation defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea5a7e3f"
      },
      "source": [
        "**Reasoning**:\n",
        "To prepare the data for embedding, I will create a sample DataFrame `df_sample` from `df_dataset` by taking `SAMPLE_SIZE` unique product descriptions, ensuring they are not empty, and then reset its index.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7974ae51",
        "outputId": "d7dae4c5-4b56-4304-bb3e-14e203106d43"
      },
      "source": [
        "df_dataset_clean = df_dataset[df_dataset['Description'].astype(bool)].copy()\n",
        "\n",
        "# Take a sample of unique descriptions\n",
        "if len(df_dataset_clean['Description'].unique()) > SAMPLE_SIZE:\n",
        "    df_sample = df_dataset_clean.drop_duplicates(subset=['Description']).sample(n=SAMPLE_SIZE, random_state=42).reset_index(drop=True)\n",
        "else:\n",
        "    df_sample = df_dataset_clean.drop_duplicates(subset=['Description']).reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(f\"Created df_sample with {len(df_sample)} unique product descriptions.\")\n",
        "print(\"--- df_sample Head ---\")\n",
        "print(df_sample.head())\n",
        "print(\"--- df_sample Info ---\")\n",
        "df_sample.info()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created df_sample with 3864 unique product descriptions.\n",
            "--- df_sample Head ---\n",
            "  InvoiceNo StockCode                          Description  Quantity  \\\n",
            "0    536365    85123A    white hanging heart tlight holder         6   \n",
            "1    536365     71053                  white metal lantern         6   \n",
            "2    536365    84406B       cream cupid hearts coat hanger         8   \n",
            "3    536365    84029G  knitted union flag hot water bottle         6   \n",
            "4    536365    84029E        red woolly hottie white heart         6   \n",
            "\n",
            "          InvoiceDate  UnitPrice  CustomerID         Country  \n",
            "0 2010-12-01 08:26:00       2.55     17850.0  United Kingdom  \n",
            "1 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
            "2 2010-12-01 08:26:00       2.75     17850.0  United Kingdom  \n",
            "3 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
            "4 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
            "--- df_sample Info ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3864 entries, 0 to 3863\n",
            "Data columns (total 8 columns):\n",
            " #   Column       Non-Null Count  Dtype         \n",
            "---  ------       --------------  -----         \n",
            " 0   InvoiceNo    3864 non-null   object        \n",
            " 1   StockCode    3864 non-null   object        \n",
            " 2   Description  3864 non-null   object        \n",
            " 3   Quantity     3864 non-null   int64         \n",
            " 4   InvoiceDate  3864 non-null   datetime64[ns]\n",
            " 5   UnitPrice    3075 non-null   float64       \n",
            " 6   CustomerID   3864 non-null   float64       \n",
            " 7   Country      3864 non-null   object        \n",
            "dtypes: datetime64[ns](1), float64(2), int64(1), object(4)\n",
            "memory usage: 241.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85377de1"
      },
      "source": [
        "**Reasoning**:\n",
        "To ensure robust embedding generation, I will define a function `embed_with_retry` that encapsulates the Gemini API call with retry logic, as specified in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d226ce21",
        "outputId": "0ca36225-73f6-4841-8e0f-ca57c65ba699"
      },
      "source": [
        "def embed_with_retry(texts_to_embed, model_name, task_type, max_retries, retry_delay_seconds=5):\n",
        "    retry_count = 0\n",
        "    while retry_count <= max_retries:\n",
        "        try:\n",
        "            response = genai.embed_content(\n",
        "                model=model_name,\n",
        "                content=texts_to_embed,\n",
        "                task_type=task_type\n",
        "            )\n",
        "            return response['embedding']\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating embeddings (Attempt {retry_count + 1}/{max_retries + 1}): {e}\")\n",
        "            retry_count += 1\n",
        "            if retry_count <= max_retries:\n",
        "                time.sleep(retry_delay_seconds)\n",
        "            else:\n",
        "                print(f\"Max retries reached for batch. Returning None for this batch.\")\n",
        "                return None # Return None if all retries fail\n",
        "\n",
        "print(\"Defined embed_with_retry function.\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined embed_with_retry function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "809f6110"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `embed_with_retry` function is defined and the `df_sample` is ready, I will prepare the descriptions, process them in batches using `ThreadPoolExecutor` with the defined retry logic, and store the generated embeddings in a new column in `df_sample`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "3d7d62d713564809838d28f34bd93db0",
            "a5da3fd56e504f4fb68cfae0df2152a2",
            "bbd80782360949a6909b4dbb88e9490c",
            "3d03751a1bc34ce5a44635de70f1ebd0",
            "eb5f678823ad41f3b0fc3a01af93fff0",
            "67975d8fec5f4b7db71df37095dec362",
            "1ca5d0e3341a4d19ab67fb3ff405b61c",
            "fca8690810834b17bd83d09c33a5c8d0",
            "decc37a73d304c0eb7133302ab14fd72",
            "b4cffe05495e45b990cede2e431cca81",
            "d9ae6a3fef084a8680173d2fb4a34add"
          ]
        },
        "id": "79392b5d",
        "outputId": "6c421869-fcdc-4565-a5a4-6f26f23bf73b"
      },
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "# 5. Prepare descriptions from df_sample for embedding\n",
        "descriptions_to_embed = df_sample['Description'].astype(str).tolist()\n",
        "\n",
        "# 6. Initialize an empty list for all embeddings\n",
        "all_embeddings = [None] * len(descriptions_to_embed) # Pre-allocate space for embeddings\n",
        "\n",
        "# Prepare batches for concurrent processing\n",
        "batches = []\n",
        "for i in range(0, len(descriptions_to_embed), BATCH_SIZE):\n",
        "    batches.append((i, descriptions_to_embed[i : i + BATCH_SIZE]))\n",
        "\n",
        "print(f\"Total batches to process: {len(batches)}\")\n",
        "\n",
        "# 7. Use ThreadPoolExecutor for parallel processing\n",
        "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "    future_to_batch = {\n",
        "        executor.submit(\n",
        "            embed_with_retry,\n",
        "            batch_texts,\n",
        "            'models/text-embedding-004',\n",
        "            'retrieval_document',\n",
        "            MAX_RETRIES\n",
        "        ): (start_idx, batch_texts)\n",
        "        for start_idx, batch_texts in batches\n",
        "    }\n",
        "\n",
        "    for future in tqdm(future_to_batch, desc=\"Generating embeddings\"):\n",
        "        start_idx, _ = future_to_batch[future]\n",
        "        try:\n",
        "            batch_embeddings = future.result()\n",
        "            if batch_embeddings is not None:\n",
        "                # Place embeddings in the correct position in all_embeddings\n",
        "                for j, emb in enumerate(batch_embeddings):\n",
        "                    all_embeddings[start_idx + j] = emb\n",
        "            else:\n",
        "                # Mark as failed if batch_embeddings is None (all retries failed)\n",
        "                print(f\"Failed to get embeddings for batch starting at index {start_idx}\")\n",
        "        except Exception as exc:\n",
        "            print(f\"Batch starting at index {start_idx} generated an exception: {exc}\")\n",
        "\n",
        "\n",
        "# 8. Add the all_embeddings list as a new column\n",
        "df_sample['Description_Embedding'] = all_embeddings\n",
        "\n",
        "# 9. Print the head of df_sample and its info\n",
        "print(\"\\n--- df_sample Head with Embeddings ---\")\n",
        "print(df_sample.head())\n",
        "print(\"\\n--- df_sample Info with Embeddings ---\")\n",
        "df_sample.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total batches to process: 78\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating embeddings:   0%|          | 0/78 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d7d62d713564809838d28f34bd93db0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error generating embeddings (Attempt 1/4): HTTPConnectionPool(host='localhost', port=41443): Read timed out. (read timeout=60.0)\n",
            "Error generating embeddings (Attempt 1/4): HTTPConnectionPool(host='localhost', port=41443): Read timed out. (read timeout=60.0)\n",
            "Error generating embeddings (Attempt 2/4): HTTPConnectionPool(host='localhost', port=41443): Read timed out. (read timeout=60.0)\n",
            "Error generating embeddings (Attempt 2/4): HTTPConnectionPool(host='localhost', port=41443): Read timed out. (read timeout=60.0)\n"
          ]
        }
      ]
    }
  ]
}